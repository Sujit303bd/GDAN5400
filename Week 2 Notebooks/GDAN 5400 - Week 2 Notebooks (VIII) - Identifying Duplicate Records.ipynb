{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c907206",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gdsaxton/GDAN5400/blob/main/Week%202%20Notebooks/GDAN%205400%20-%20Week%202%20Notebooks%20%28VIII%29%20-%20Identifying%20Duplicate%20Records.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58dcaba",
   "metadata": {},
   "source": [
    "This notebook provides recipes for identifying duplicate records in PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9da7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import datetime\n",
    "print (\"Current date and time : \", datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af03858",
   "metadata": {},
   "source": [
    "# Load Packages and Set Working Directory\n",
    "Import several necessary Python packages. We will be using the <a href=\"http://pandas.pydata.org/\">Python Data Analysis Library,</a> or <i>PANDAS</i>, extensively for our data manipulations in this and future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab477ac",
   "metadata": {},
   "source": [
    "<br>\n",
    "PANDAS allows you to set various options for, among other things, inspecting the data. I like to be able to see all of the columns. Therefore, I typically include this line at the top of all my notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://pandas.pydata.org/pandas-docs/stable/options.html\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', 250)\n",
    "pd.set_option('display.max_info_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b452531",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8420eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# NOTE: replace `https://github.com/` with `https://raw.githubusercontent.com`\n",
    "# https://github.com/gdsaxton/GDAN5400/blob/main/Coding%20Assignment%201/final_insurance_fraud.xlsx\n",
    "url = 'https://raw.githubusercontent.com/gdsaxton/GDAN5400/main/Coding%20Assignment%201/final_insurance_fraud.xlsx'\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open('final_insurance_fraud.xlsx', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('final_insurance_fraud.xlsx', engine='openpyxl')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de859d30",
   "metadata": {},
   "source": [
    "# Identifying Duplicate Records in PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8108861",
   "metadata": {},
   "source": [
    "**[ChatGPT prompt]** `How can I identify duplicate records in PANDAS?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21239231",
   "metadata": {},
   "source": [
    "In PANDAS, you can identify duplicates in a DataFrame or Series using the `duplicated()` method. Below are some of the key techniques you should know. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee1af69",
   "metadata": {},
   "source": [
    "### Using `duplicated()`\n",
    "The `duplicated()` method marks duplicates as True and unique values as False. Note that the `duplicated()` method only *flags* duplicates but does not remove them.\n",
    "\n",
    "By default, `duplicated()` flags as False the first occurrence of a duplicate and marks subsequent ones as True. You can change this behavior using the `keep` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd3263",
   "metadata": {},
   "source": [
    "### Check for duplicates across all columns\n",
    "There are no duplicate rows identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated()\n",
    "duplicates.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a86464",
   "metadata": {},
   "source": [
    "Note that `duplicates` is not a dataset; it is a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad38eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))\n",
    "print(type(duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ca8fd",
   "metadata": {},
   "source": [
    "### Check for Duplicates Across Specific Columns\n",
    "To find duplicates based on specific column(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae13908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates based on the 'Name' column\n",
    "duplicates = df.duplicated(subset=['Surname'])\n",
    "print(duplicates.value_counts(), '\\n')\n",
    "duplicates[25:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c4cd1",
   "metadata": {},
   "source": [
    "### Count duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicates = df.duplicated(subset=['Surname']).sum()\n",
    "print(f\"Number of duplicates: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2bdecd",
   "metadata": {},
   "source": [
    "### Flag All Duplicates\n",
    "The `duplicated(keep=False)` method in pandas identifies all occurrences of duplicate rows in a DataFrame or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark all occurrences of duplicates\n",
    "all_duplicates = df.duplicated(subset=['Surname'], keep=False)\n",
    "print('Number of duplicates:', len(all_duplicates), '\\n')\n",
    "print(all_duplicates.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d879d",
   "metadata": {},
   "source": [
    "### Add a column to indicate duplicates\n",
    "Adding a column with duplicated() is useful for:\n",
    "- Analyzing Duplicates: You can inspect which rows are flagged as duplicates.\n",
    "- Conditional Operations: Filter, modify, or drop rows based on their duplicate status.\n",
    "- Debugging Data Quality: Quickly identify and investigate duplicate rows in your dataset.\n",
    "\n",
    "In these methods, we will still be working with a PANDAS *dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac4ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to indicate duplicates\n",
    "df['Is_Duplicate'] = df.duplicated(subset=['Surname'], keep=False)\n",
    "df['Is_Duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676687a4",
   "metadata": {},
   "source": [
    "In this example we also *selecting* all records that are duplicates, then sorting the dataframe by `Surname`, and then displaying the first 6 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2709f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Is_Duplicate'] == True].sort_values('Surname')[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to indicate duplicates\n",
    "# Note that we are overwriting our column `Is_Duplicate`\n",
    "df['Is_Duplicate'] = df.duplicated(subset=['Surname', 'Street Address'], keep=False)\n",
    "df[df['Is_Duplicate'] == True]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
